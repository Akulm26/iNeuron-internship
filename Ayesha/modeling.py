# -*- coding: utf-8 -*-
"""modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KkCNSUMUe75V2gt1AOPBYFKuRP-UJ7BS
"""

#!pip install pycaret[full]

import pycaret
import pandas as pd

train = pd.read_csv("/content/drive/MyDrive/ineuron moedling /train_modified.csv")

print('PyCaret: %s' % pycaret.__version__)

from pycaret.regression import *

train.head()

train1 = train[train["source"]=='train']

#train1 = train1.drop('source', axis = 1)
train1

train1.dtypes

reg1 = setup(data = train1, target = 'Item_Outlet_Sales')

reg1 = setup(data = train1, target = 'Item_Outlet_Sales', numeric_features = ['Years_Established'])

best = compare_models()

top3 = compare_models(n_select = 3)

#Gradient boosting regression


from sklearn.model_selection import train_test_split 
Y = train["Item_Outlet_Sales"]
X = train.drop("Item_Outlet_Sales", axis = 1)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.20, random_state=0)
  
# import numpy as np
# def MAPE(Y_actual,Y_Predicted):
#     mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100
#     return mape
  
from sklearn.ensemble import GradientBoostingRegressor
GR = GradientBoostingRegressor() 
gmodel = GR.fit(X_train, Y_train) 
g_predict = gmodel.predict(X_test)
# GB_MAPE = MAPE(Y_test,g_predict)
# Accuracy = 100 - GB_MAPE
# print("MAPE: ",GB_MAPE)
# print('Accuracy of Linear Regression: {:0.2f}%.'.format(Accuracy))

import numpy as np
def RMSE(Y_actual,Y_Predicted):
    RMSE = np.sqrt(((Y_actual - Y_Predicted)**2).mean())
    return RMSE

#RMSE(Y_test, g_predict)
import sklearn
from sklearn.metrics import mean_squared_error

np.sqrt(sklearn.metrics.mean_squared_error(Y_test, g_predict))

from sklearn.ensemble import GradientBoostingRegressor
from sklearn import tree
from sklearn.model_selection import GridSearchCV
import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

##3 Hyperparameter tuning

GBR=GradientBoostingRegressor()
search_grid={'n_estimators':[500,1000,2000],'learning_rate':[.001,0.01,.1],'max_depth':[1,2,4],'subsample':[.5,.75,1],'random_state':[1]}
search=GridSearchCV(estimator=GBR,param_grid=search_grid,scoring='neg_mean_squared_error',n_jobs= 5)

search.fit(X_train, Y_train)

np.sqrt(abs(search.best_score_))

search.best_params_

GR_tuned = GradientBoostingRegressor(learning_rate= 0.01, max_depth=4, n_estimators=500, random_state=1, subsample=0.5)
tuned_model = GR_tuned.fit(X_train, Y_train) 
g_predict_tuned = tuned_model.predict(X_test)

np.sqrt(sklearn.metrics.mean_squared_error(Y_test, g_predict_tuned))

import pickle
filename = 'finalized_model.sav'
pickle.dump(tuned_model, open(filename, 'wb'))

#/content/finalized_model.sav
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(X_test, Y_test)
print(result)